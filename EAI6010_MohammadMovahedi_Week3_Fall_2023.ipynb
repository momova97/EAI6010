{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/momova97/EAI6010/blob/main/EAI6010_MohammadMovahedi_Week3_Fall_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7I4BGoRA-Fs"
      },
      "source": [
        "<center>\n",
        "<div style=\"font-family: 'Times New Roman', serif; text-align: center; margin: auto;\">\n",
        "  <img src=\"https://image-tc.galaxy.tf/wipng-3jcsiz4vzvffnpa7dfizxcdbp/northeastern-university.png\" alt=\"Northeastern University Logo\" style=\"width: 200px; margin-bottom: 1em;\">\n",
        "  <h1 style=\"font-size: 2.5em; margin-bottom: 0.5em;\">Assignment 3</h1>\n",
        "  <h2 style=\"font-size: 1.5em; margin-bottom: 0.3em;\">EAI6010  - Applications of Artificial Intelligence</h2>\n",
        "  <h2 style=\"font-size: 1.5em; margin-bottom: 0.3em;\">Mohammad Hossein Movahedi</h2>\n",
        "  <h3 style=\"font-size: 1.2em; margin-bottom: 0.3em; font-style: italic;\">Lecturer: Prof. Vladimir Shapiro</h3>\n",
        "  <h3 style=\"font-size: 1em; margin-top: 2em; font-weight: bold; text-align: center;\">Fall 2023</h3>\n",
        "</div>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSJtum_SA-Ft"
      },
      "source": [
        "## Table of Contents\n",
        "1. [Introduction](#Introduction)\n",
        "2. [Data Cleaning](#Data-Cleaning)\n",
        "3. [Data Analysis](#Data-Analysis)\n",
        "4. [Results and Discussion](#Results-and-Discussion)\n",
        "5. [Conclusion](#Conclusion)\n",
        "6. [References](#References)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSmPeNabA-Ft"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbThxb4kA-Ft"
      },
      "source": [
        "This assignment delves into the fascinating world of Natural Language Processing (NLP), a field at the intersection of computer science, artificial intelligence, and linguistics. NLP enables computers to understand, interpret, and respond to human language in a meaningful way. Through this assignment, you will gain hands-on experience in using NLP techniques for text analysis, employing tools such as the Gutenberg corpus and the Inaugural corpus within the NLTK package."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb7iVbKeA-Ft"
      },
      "source": [
        "## Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-qAam-eA-Fu"
      },
      "source": [
        "For this assignment, I will be using the [Gutenberg](https://www.gutenberg.org/) corpus, a collection of texts from the 18th century, to explore the relationship between language and the world around us. It doen't need a data cleaning step as the corpus is already clean."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWiS3XJjA-Fu"
      },
      "source": [
        "## Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'm embarking on an NLP assignment focused on the text courpus. The first crucial step involves data cleaning, ensuring the text is primed for precise analysis. This process will include standardizing formats, removing irrelevant elements, and preparing the data for in-depth exploration of its linguistic features."
      ],
      "metadata": {
        "id": "yGqFgVtRxahk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Below is the code for Q1**"
      ],
      "metadata": {
        "id": "sACMO6viC0kZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's import the necessary libraries."
      ],
      "metadata": {
        "id": "t35zO3MpuzZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Necessary Libraries\n",
        "import nltk\n",
        "from nltk.corpus import gutenberg\n",
        "from collections import Counter\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "EvhuWxTvuiYn"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then let's load the text data. by downloading the Gutenberg corpus tool from the NLTK website."
      ],
      "metadata": {
        "id": "D5xkoOdru-mr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('gutenberg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cVY517eux0D",
        "outputId": "a4fd54bc-a876-43bd-daed-b35fd62eae35"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After that, let's load the text data from the corpus."
      ],
      "metadata": {
        "id": "U0pZVISXv1Gi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Use the texts in the corpus\n",
        "corpus = nltk.corpus.gutenberg.words()\n",
        "corpus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3jm4QC_vrDN",
        "outputId": "98df562c-fa75-452f-dcfd-2752453bdf3e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']', ...]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's count the frequency of each word in the corpus. I will use the FreqDist function from the nltk library to count the frequency of each word in the corpus. and then calculate the relative frequency of each modal."
      ],
      "metadata": {
        "id": "XDvByp0Xw6kL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a table displaying relative frequency\n",
        "FeqDist = pd.Series(nltk.FreqDist(corpus)).sort_values(ascending=False)\n",
        "\n",
        "#filter the table on  which “modals” (can, could, may, might, will, would, and should) appear in each of the texts provided in the corpus.\n",
        "modals = ['can', 'could', 'may', 'might', 'will', 'would', 'should']\n",
        "ModalsDist = FeqDist[FeqDist.index.isin(modals)]\n",
        "ModalsDist = pd.DataFrame(ModalsDist, columns=['frequency'])\n",
        "ModalsDist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "4mSqBkYjv6YF",
        "outputId": "9568c4a6-47f7-4eee-db74-caceec7244e7"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        frequency\n",
              "will         7130\n",
              "would        3932\n",
              "could        3528\n",
              "should       2496\n",
              "may          2435\n",
              "can          2163\n",
              "might        1938"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fac46457-fc8f-4d7e-9066-36eb37dbf7da\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>will</th>\n",
              "      <td>7130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>would</th>\n",
              "      <td>3932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>could</th>\n",
              "      <td>3528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>should</th>\n",
              "      <td>2496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>may</th>\n",
              "      <td>2435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>can</th>\n",
              "      <td>2163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>might</th>\n",
              "      <td>1938</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fac46457-fc8f-4d7e-9066-36eb37dbf7da')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fac46457-fc8f-4d7e-9066-36eb37dbf7da button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fac46457-fc8f-4d7e-9066-36eb37dbf7da');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e8dedaa9-ee9a-4ab8-b172-81a03189090b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e8dedaa9-ee9a-4ab8-b172-81a03189090b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e8dedaa9-ee9a-4ab8-b172-81a03189090b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's find the two modals with the largest span of relative frequencies."
      ],
      "metadata": {
        "id": "7hIpUS5m2Wr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Determine two modals with the largest span of relative frequencies'\n",
        "Modals = ['can', 'could', 'may', 'might', 'will', 'would', 'should']\n",
        "#\"Relative frequency\" = the number of occurrences of a given modal divided by the total number of modals in the given text.\n",
        "Dic = {}\n",
        "for modal in Modals:\n",
        "  Dic[modal] = ModalsDist.loc[modal, 'frequency'] / ModalsDist['frequency'].sum()\n",
        "#print(Dic)\n",
        "#Determine two modals with the largest span of relative frequencies\n",
        "Dic = sorted(Dic.items(), key=lambda kv: kv[1], reverse=True)\n",
        "#print(Dic)\n",
        "# Print the two modal with the largest span of relative frequencies\n",
        "print(Dic[0])\n",
        "print(Dic[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIuhwMDjxvHg",
        "outputId": "4d1b3e66-b105-4e68-994a-0ec603d1ddea"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('will', 0.30183727034120733)\n",
            "('might', 0.08204216408432817)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the Code for Part E"
      ],
      "metadata": {
        "id": "kzH2mW6t2R1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "modal_frequencies = {modal: Counter() for modal in modals}\n",
        "#print(modal_frequencies)\n",
        "\n",
        "# Analyze each text in the Gutenberg corpus\n",
        "for fileid in gutenberg.fileids():\n",
        "    words = [word.lower() for word in gutenberg.words(fileid)]\n",
        "    for modal in modals:\n",
        "        modal_frequencies[modal][fileid] = words.count(modal)\n",
        "\n",
        "#print(modal_frequencies)\n",
        "\n",
        "# Create a DataFrame to display relative frequencies\n",
        "df = pd.DataFrame(modal_frequencies)\n",
        "\n",
        "# Calculate total modals for each text\n",
        "df['total_modals'] = df.sum(axis=1)\n",
        "\n",
        "# Calculate relative frequencies\n",
        "for modal in modals:\n",
        "    df[modal] = df[modal] / df['total_modals']\n",
        "\n",
        "# Find two modals with the largest span of relative frequencies\n",
        "spans = {modal: df[modal].max() - df[modal].min() for modal in modals}\n",
        "largest_span_modals = sorted(spans, key=spans.get, reverse=True)[:2]\n",
        "\n",
        "# Select the texts for the most frequently used modal among the two\n",
        "most_used_modal = largest_span_modals[0]\n",
        "most_text = df[most_used_modal].idxmax()\n",
        "least_text = df[most_used_modal].idxmin()\n",
        "\n",
        "# Print results\n",
        "print(f\"Two modals with the largest span: {largest_span_modals}\")\n",
        "print(f\"Text with the most usage of '{most_used_modal}': {most_text}\")\n",
        "print(f\"Text with the least usage of '{most_used_modal}': {least_text}\")\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNgvZybt1Uyg",
        "outputId": "9b856baa-ea00-4bf0-dbe9-5e65b4958e51"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'can': Counter(), 'could': Counter(), 'may': Counter(), 'might': Counter(), 'will': Counter(), 'would': Counter(), 'should': Counter()}\n",
            "Two modals with the largest span: ['will', 'can']\n",
            "Text with the most usage of 'will': bible-kjv.txt\n",
            "Text with the least usage of 'will': blake-poems.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's important to note, In the King James Bible, \"will\" is used to show God's power and plans, fitting its serious and old-fashioned style. In William Blake's poems, \"will\" shows personal wishes and feelings, matching his dreamy and emotional writing. So, \"will\" in the Bible is about God's commands, but in Blake's poetry, it's about personal hopes and challenging norms."
      ],
      "metadata": {
        "id": "8DTE02oyvSPW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Below is the Code for Q2**"
      ],
      "metadata": {
        "id": "3oPRmyZ2C7ew"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbAc34NoA-Fu"
      },
      "source": [
        "Nunc in velit neque. Cras dui nunc, maximus non ornare a, tempor quis lorem. Morbi feugiat sodales magna quis lacinia. Pellentesque porttitor ex id nisi pretium lacinia. Proin nec sapien volutpat, porttitor purus nec, elementum enim.  \n",
        "\n",
        "<strong>Q1 Pellentesque at vestibulum augue, non gravida tellus?</strong>\n",
        "\n",
        "Pellentesque sed metus risus. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Donec cursus eleifend neque, id interdum metus eleifend in.\n",
        "\n",
        "<strong>A1 Pellentesque at vestibulum augue, non gravida tellus.</strong>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "bK4OapfxA-Fu",
        "outputId": "746a077d-d716-47cb-978a-0546e2adaf6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]   Package inaugural is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The word 'supporting' has the most synonyms: 37\n",
            "The word 'americans' has the most hyponyms: 109\n",
            "Synonyms:\n",
            "citizens: {'citizen'}\n",
            "president: {'chair', 'President', 'United_States_President', 'president', 'Chief_Executive', 'chairwoman', 'chairperson', 'President_of_the_United_States', 'prexy', 'chairman'}\n",
            "americans: {'American_English', 'American_language', 'American'}\n",
            "generation: {'contemporaries', 'generation', 'coevals', 'genesis', 'propagation', 'multiplication'}\n",
            "forebears: {'forebear', 'forbear'}\n",
            "revolution: {'rotation', 'revolution', 'gyration'}\n",
            "committed: {'trust', 'institutionalize', 'attached', 'entrust', 'put', 'charge', 'confide', 'place', 'give', 'pull', 'committed', 'practice', 'perpetrate', 'invest', 'institutionalise', 'dedicate', 'send', 'devote', 'intrust', 'consecrate', 'commit'}\n",
            "powerful: {'muscular', 'right', 'powerful', 'mighty', 'hefty', 'brawny', 'herculean', 'knock-down', 'potent', 'mightily', 'sinewy'}\n",
            "supporting: {'subscribe', 'patronize', 'plump_for', 'patronage', 'affirm', 'endorse', 'hold', 'corroborate', 'keep_going', 'bear', 'bear_out', 'digest', 'indorse', 'endure', 'confirm', 'sustain', 'hold_up', 'patronise', 'defend', 'stick_out', 'plunk_for', 'stand', 'back_up', 'put_up', 'load-bearing', 'tolerate', 'underpin', 'brook', 'encouraging', 'back', 'stomach', 'suffer', 'support', 'substantiate', 'fend_for', 'abide', 'supporting'}\n",
            "themselves: set()\n",
            "\n",
            "Hyponyms:\n",
            "citizens: {'freewoman', 'repatriate', 'voter', 'active_citizen', 'civilian', 'thane', 'freeman', 'private_citizen', 'elector'}\n",
            "president: {'ex-president', 'vice_chairman', 'Kalon_Tripa'}\n",
            "americans: {'Keystone_Stater', 'Badger', 'Alaskan', 'Delawarean', 'Sooner', 'Mainer', 'Carolinian', 'Missourian', 'Appalachian', 'AAVE', 'West_Indian', 'Latino', 'Tory', 'New_Jerseyite', 'New_Jerseyan', 'South_Dakotan', 'Bostonian', 'Alabaman', 'Oklahoman', 'Bluegrass_Stater', 'Hawaiian', 'West_Virginian', 'Michigander', 'Kansan', 'Utahan', 'Rhode_Islander', 'Wisconsinite', 'Louisianan', 'North_Dakotan', 'Northerner', 'Wolverine', 'Mississippian', 'Nevadan', 'Franco-American', 'Hispanic', 'Afro-American', 'Iowan', 'Arkansan', 'Californian', 'New_Yorker', 'Hoosier', 'Beaver', 'Volunteer', 'Illinoisan', 'Creole', 'Virginian', 'Nebraskan', 'African-American', 'Louisianian', 'Arizonian', 'Tennessean', 'North_Carolinian', 'Arizonan', 'Georgian', 'Montanan', 'Yank', 'South_American', 'New_Hampshirite', 'German_American', 'Yankee-Doodle', 'Ohioan', 'South_Carolinian', 'Southerner', 'Yankee', 'Black_Vernacular', 'Marylander', 'Ebonics', 'Arkansawyer', 'Black_English_Vernacular', 'Puerto_Rican', 'Asian_American', 'Garden_Stater', 'Alabamian', 'New_Englander', 'Latin_American', 'Kentuckian', 'Mesoamerican', 'North_American', 'Tarheel', 'Hispanic_American', 'Coloradan', 'Pennsylvanian', 'Connecticuter', 'African_American_English', 'African_American_Vernacular_English', 'Gopher', 'Granite_Stater', 'Oregonian', 'Delawarian', 'Floridian', 'Spanish_American', 'Bay_Stater', 'Buckeye', 'Vermonter', 'Down_Easter', 'Washingtonian', 'Idahoan', 'Wyomingite', 'Minnesotan', 'Anglo-American', 'New_Mexican', 'Texan', 'Indianan', 'Black_English', 'African_American', 'Cornhusker', 'Black_American', 'Black_Vernacular_English', 'Nisei'}\n",
            "generation: {'biogenesis', 'baby-boom_generation', 'gen_X', 'posterity', 'baby_boom', 'youth_culture', 'peer_group', 'generation_X', 'biogeny'}\n",
            "forebears: {'grandparent', 'great_grandparent'}\n",
            "revolution: {'spin', 'levorotation', 'orbital_motion', 'axial_rotation', 'axial_motion', 'roll', 'counterclockwise_rotation', 'green_revolution', 'dextrorotation', 'orbital_rotation', 'Cultural_Revolution', 'clockwise_rotation', 'counterrevolution', 'Great_Proletarian_Cultural_Revolution'}\n",
            "committed: {'obligate', 'shelter', 'rededicate', 'tie_up', 'consign', 'charge', 'roll_over', 'speculate', 'job', 'fund', 'hospitalize', 'apply', 'hospitalise', 'vow', 'buy_into', 'make', 'consecrate', 'recommit', 'commend'}\n",
            "powerful: set()\n",
            "supporting: {'patronize', 'pole', 'sponsor', 'stick_up', 'stand_up', 'propping_up', 'bear_up', 'further', 'carry', 'patronise', 'prop', 'rationalize', 'underpin', 'bring_home_the_bacon', 'hold_still_for', 'block', 'boost', 'undergird', 'brace', 'excuse', 'truss', 'assist', 'shore_up', 'indorse', 'sit_out', 'justify', 'suspension', 'prop_up', 'see_through', 'fund', 'hanging', 'bracket', 'back_up', 'shop', 'back', 'chock', 'apologize', 'take_a_joke', 'swallow', 'shore', 'champion', 'second', 'uphold', 'apologise', 'take_lying_down', 'shew', 'vouch', 'scaffold', 'dangling', 'provide', 'promote', 'defend', 'encourage', 'frequent', 'subsidise', 'buoy', 'subsidize', 'pay', 'show', 'advance', 'help', 'live_with', 'shoring_up', 'endorse', 'shoring', 'warrant', 'buy_at', 'rationalise', 'verify', 'stand_for', 'validate', 'buoy_up', 'prove', 'accept', 'document', 'aid', 'guarantee', 'establish', 'shop_at', 'demonstrate'}\n",
            "themselves: set()\n"
          ]
        }
      ],
      "source": [
        "# nltk is a tool that helps us play with words in books or speeches\n",
        "from nltk.corpus import inaugural\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.corpus import wordnet as wn\n",
        "nltk.download('wordnet')\n",
        "# A:  download the inaugural speeches\n",
        "nltk.download('inaugural')\n",
        "\n",
        "# B: We're going to look at President Kennedy's speech, which is like picking out his book from a library\n",
        "kennedy_speech = inaugural.words('1961-Kennedy.txt')\n",
        "\n",
        "# C: Now we want to find the 10 longest and most popular words in his speech\n",
        "long_words = [word.lower() for word in kennedy_speech if len(word) > 7]  # Only pick words longer than 7 letters\n",
        "fdist = FreqDist(long_words)  # Count how many times each word appears\n",
        "most_common_long = fdist.most_common(10)  # Pick the 10 words that appear the most\n",
        "\n",
        "# D: We're going to use WordNet, which is like a thesaurus to find synonyms\n",
        "max_syn_count = 0  # This is placeholder for the count of the word with the most synonyms\n",
        "word_with_max_syn = ''  # This is palaceholder for the word with the largest number of synonyms\n",
        "\n",
        "# E: We're going to make a list of all the words that mean the same thing for our top 10 words\n",
        "synonyms = {}  # This is like our notebook to write down all the synonyms\n",
        "for word, _ in most_common_long:\n",
        "    synsets = wn.synsets(word)  # Find all the groups of synonyms for our word\n",
        "    all_synonyms = set(lemma.name() for synset in synsets for lemma in synset.lemmas())  # Write down all the synonyms\n",
        "    synonyms[word] = all_synonyms  # Put them in our list\n",
        "    if len(all_synonyms) > max_syn_count:  # If this word has more synonyms than the current champion...\n",
        "        max_syn_count = len(all_synonyms)  # ...update the synonym scoreboard...\n",
        "        word_with_max_syn = word  # ...and write down the new winner\n",
        "\n",
        "# Print the word with the largest number of synonyms and the count\n",
        "print(f\"The word '{word_with_max_syn}' has the most synonyms: {max_syn_count}\")\n",
        "\n",
        "# F: We also want to find words that are more specific types of our word, like if 'vehicle' was our word, 'car' would be a more specific type\n",
        "hyponyms = {}  # This is another notebook for the specific types of words\n",
        "for word, _ in most_common_long:\n",
        "    synsets = wn.synsets(word)  # Again we find all the groups of synonyms\n",
        "    all_hyponyms = set(lemma.name() for synset in synsets for hyponym in synset.hyponyms() for lemma in hyponym.lemmas())  # Now we write down all the specific types\n",
        "    hyponyms[word] = all_hyponyms  # And put them in our notebook\n",
        "\n",
        "# G: Now let's find out which word has the most specific types\n",
        "max_hypo_count = 0  # Our scoreboard for the most specific types\n",
        "word_with_max_hypo = ''  # The name of the winner\n",
        "\n",
        "for word, hypo_set in hyponyms.items():\n",
        "    if len(hypo_set) > max_hypo_count:  # If this word has more specific types than the current champion...\n",
        "        max_hypo_count = len(hypo_set)  # ...update the scoreboard...\n",
        "        word_with_max_hypo = word  # ...and write down the new winner\n",
        "\n",
        "# Print the word with the largest number of hyponyms and the count\n",
        "print(f\"The word '{word_with_max_hypo}' has the most hyponyms: {max_hypo_count}\")\n",
        "\n",
        "# H: Reflect on the results - This is where you think about what you found, like looking back at your adventure in a diary\n",
        "print(\"Synonyms:\")\n",
        "for word, syn_set in synonyms.items():\n",
        "    print(f\"{word}: {syn_set}\")\n",
        "\n",
        "print(\"\\nHyponyms:\")\n",
        "for word, hypo_set in hyponyms.items():\n",
        "    print(f\"{word}: {hypo_set}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G15Z5S27A-Fv"
      },
      "source": [
        "## Results and Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-ZZlOmTA-Fv"
      },
      "source": [
        "In analyzing President Kennedy's inaugural speech through NLTK's corpus and WordNet, we find that the word 'supporting' stands out with the most synonyms, suggesting a rich variety of ways to convey the concept of aid or backing within the English language. This diversity reflects the speech's emphasis on the collective effort and mutual assistance, resonating with the theme of national unity and cooperation.\n",
        "\n",
        "On the other hand, 'americans' has the most hyponyms, indicating a broad spectrum of identities and groups that constitute the American populace. This underlines the speech's inclusive nature, acknowledging the diverse tapestry of people that form the United States.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqujkkbMA-Fv"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruiCK6y0A-Fv"
      },
      "source": [
        "In this NLP assignment, I explored how language reflects themes and styles in different texts. Using the Gutenberg corpus, I found that the modal verb \"will\" varies significantly between texts, illustrating God's command in the King James Bible and personal desires in William Blake's poetry. This highlights how the same word can carry different meanings depending on the context. In President Kennedy's inaugural speech analysis, the word 'supporting' emerged with the most synonyms, emphasizing the speech's focus on collective effort and aid. The word 'americans' showed the most hyponyms, reflecting the diversity of the American population, aligning with the speech's inclusive nature. These analyses using NLP tools like NLTK and WordNet demonstrate the complexity and richness of language, revealing how word choice in literature and speeches can mirror societal values and historical contexts. This assignment underlines the challenges and nuances in NLP, showcasing its potential to unravel deeper linguistic and thematic insights from texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8mqYFgKA-Fv"
      },
      "source": [
        "## References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JI95JCNdA-Fv"
      },
      "source": [
        "James, K. (2023). OFFICIAL KING JAMES BIBLE ONLINE. [online] Kingjamesbibleonline.org. Available at: https://www.kingjamesbibleonline.org/ [Accessed 19 Nov. 2023].\n",
        "\n",
        "Blakearchive.org. (2023). The William Blake Archive. [online] Available at: https://www.blakearchive.org/ [Accessed 19 Nov. 2023].\n",
        "\n",
        "‌\n",
        "\n",
        "Jfklibrary.org. (2023). Inaugural Address, January 20, 1961 | JFK Library. [online] Available at: https://www.jfklibrary.org/archives/other-resources/john-f-kennedy-speeches/inaugural-address-19610120 [Accessed 19 Nov. 2023].\n",
        "\n",
        "‌"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}